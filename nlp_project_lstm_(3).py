# -*- coding: utf-8 -*-
"""NLP_Project_LSTM (3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rlFJ5od_i2KuP5R4ycSDLuFcolrsG2Er
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import string
import regex as re
import nltk as nltk
from nltk import corpus
from nltk.stem import PorterStemmer
device_name= tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

missing_values = ["n/a", "na", "--"]
df_hotel = pd.read_csv('tripadvisor_hotel_reviews.csv', encoding='latin-1')

df_hotel.isna().sum()

df_hotel.head(3000)

df_hotel.tail(5000)

def tokenize(text):
    split=re.split("\W+",text) 
    return split
df_hotel['review_text_split']=df_hotel['Review'].apply(lambda x: tokenize(x.lower()))
df_hotel.head(100)

nltk.download('stopwords')
stopword = nltk.corpus.stopwords.words('english')
print(stopword[:20])

def remove_stopwords(text):
    text=[word for word in text if word not in stopword]
    return text
df_hotel['review_text_stopwords'] = df_hotel['review_text_split'].apply(lambda x: remove_stopwords(x))
df_hotel.head(1000)

stemmer = nltk.stem.SnowballStemmer(language='english')
def stem_list(row):
    my_list = row['review_text_stopwords']
    stemmed_list = [stemmer.stem(word) for word in my_list]
    return (stemmed_list)

df_hotel['stemmed_review'] = df_hotel.apply(stem_list, axis=1)

df_hotel.head(1000)

df_hotel.tail(1000)

def rating_group(rate):
    group = rate['Rating']
    if rate['Rating'] > 3:
        grouped_rate = 'Good'
    elif rate['Rating'] == 3:
        grouped_rate = 'Neutral'
    elif rate['Rating'] < 3:
        grouped_rate = 'Bad'
    return (grouped_rate)

df_hotel['new_rating'] = df_hotel.apply(rating_group, axis=1)

df_hotel.head(1000)

df_hotel.tail(1000)

rating_category = pd.get_dummies(df_hotel.new_rating)
df_baru = pd.concat([df_hotel, rating_category], axis=1)
df_baru = df_baru.drop(columns='Rating')
df_baru

df_baru.dtypes

review = df_baru['stemmed_review'].values
label = df_baru[['Bad','Good','Neutral']].values
label

print(review.shape, label.shape)

from sklearn.model_selection import train_test_split
review_train, review_test,label_train, label_test = train_test_split(review, label, test_size=0.2, shuffle=False)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
     
tokenizer = Tokenizer(num_words=10000, oov_token='x')
tokenizer.fit_on_texts(review_train)
tokenizer.fit_on_texts(review_test)
     
sequence_train = tokenizer.texts_to_sequences(review_train)
sequence_test = tokenizer.texts_to_sequences(review_test)

padded_train = pad_sequences(sequence_train)
padded_test = pad_sequences(sequence_test)

model = tf.keras.Sequential([
     tf.keras.layers.Embedding(input_dim=50000, output_dim=16),
     tf.keras.layers.BatchNormalization(),
     tf.keras.layers.Dropout(0.2),
     tf.keras.layers.LSTM(128),
     tf.keras.layers.Dense(128, activation='relu'),
     tf.keras.layers.Dropout(0.5),
     tf.keras.layers.Dense(128, activation='relu'),
     tf.keras.layers.Dropout(0.5),
     tf.keras.layers.Dense(3, activation='softmax')
     ])
model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])

num_epochs = 100
class callBack(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
      if(logs.get('val_accuracy') > 0.85 and logs.get('accuracy') > 0.85):
        self.model.stop_training = True

callbacks = callBack()
history = model.fit(padded_train, label_train, batch_size=128, epochs=num_epochs, callbacks=[callbacks], validation_data=(padded_test, label_test), verbose=2)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='lower right')
plt.show()